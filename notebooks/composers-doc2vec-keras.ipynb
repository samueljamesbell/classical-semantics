{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "awsG1d0fg7gG",
    "outputId": "b5113a18-66f0-4378-d713-49c03e63a20d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "from difflib import SequenceMatcher\n",
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import requests\n",
    "from scipy.spatial import distance\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Average, Concatenate, Dense, Embedding, Flatten, Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yD1aWcQ6VdTY"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "def composers():\n",
    "  with open('../data/composers.csv', 'r') as f:\n",
    "    next(f)  # Skip headers\n",
    "    for composer_id, line in enumerate(f):\n",
    "      yield (composer_id, *line.strip().split('|'))\n",
    "      \n",
    "all_composers = list(composers())\n",
    "\n",
    "id_to_composer = {c[0]: c for c in all_composers}\n",
    "composer_to_id = {(c[0], c[1], c[2]): c for c in all_composers}\n",
    "\n",
    "# Note that this loses the fact that there are multiple composers with the same name\n",
    "name_to_composer = {c[1]: c for c in all_composers}\n",
    "\n",
    "@functools.lru_cache()\n",
    "def soup(url):\n",
    "  try:\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    return BeautifulSoup(response.text, 'html.parser')\n",
    "  except requests.HTTPError:\n",
    "    return None\n",
    "  \n",
    "@functools.lru_cache()\n",
    "def wiki_links(soup):\n",
    "  if soup is None:\n",
    "    return []\n",
    "  \n",
    "  links = []\n",
    "  for link in soup.find_all('a'):\n",
    "    href = link.get('href')\n",
    "    if href and href.startswith('/wiki'):\n",
    "      links.append(link.get('title'))\n",
    "  return links\n",
    "\n",
    "@functools.lru_cache()\n",
    "def text(soup):\n",
    "  if soup is None:\n",
    "    return ''\n",
    "  \n",
    "  paragraphs = soup.find(attrs={\"class\": \"mw-parser-output\"}).find_all('p')\n",
    "  all_text = ' '.join(list(itertools.chain.from_iterable(para.stripped_strings for para in paragraphs)))\n",
    "  return re.sub('\\[\\d*\\]', '', all_text)\n",
    "\n",
    "@functools.lru_cache()\n",
    "def tokens(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ISrLsoxlkNMw",
    "outputId": "1b561bce-a74d-4b0f-ad0b-ee68b5cef515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming Antonio Vivaldi: born 1678; died 1741; composer_id: 3379\n",
      "https://en.wikipedia.org/wiki/Antonio_Vivaldi\n"
     ]
    }
   ],
   "source": [
    "#@title Choose a composer\n",
    "\n",
    "# Capture inputs\n",
    "\n",
    "input_name = 'Antonio Vivaldi' #@param \n",
    "model_name = \"doc2vec\" #@param [\"wikipedia-links\", \"spotify\", \"doc2vec\"]\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "composer = max(all_composers, key=lambda c: similar(c[1], input_name))\n",
    "composer_id = composer[0]\n",
    "\n",
    "print('Assuming {}: born {}; died {}; composer_id: {}'.format(composer[1], composer[2], composer[3], composer[0]))\n",
    "print(composer[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sG7ublNJGzlF"
   },
   "outputs": [],
   "source": [
    "# Wikipedia and Spotify baselines\n",
    "\n",
    "def similar_wikipedia_links(composer_id):\n",
    "  print('Using wikipedia-links model')\n",
    "  composer = id_to_composer[composer_id]\n",
    "   \n",
    "  source_url = composer[-1]\n",
    "  source_text = tokens(text(soup(source_url)))\n",
    "  source_links = wiki_links(soup(source_url))\n",
    "\n",
    "  c = collections.Counter(source_links)\n",
    "\n",
    "  similar_ids = (name_to_composer[link][0]\n",
    "                 for link, _\n",
    "                 in c.most_common()\n",
    "                 if link in name_to_composer)\n",
    "  \n",
    "  return similar_ids\n",
    "\n",
    "\n",
    "def similar_spotify(composer_id):\n",
    "  print('Using spotify model')\n",
    "  return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ducbR88YlTY"
   },
   "outputs": [],
   "source": [
    "# Build vocab\n",
    "\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "def build_vocab():\n",
    "    all_tokens = itertools.chain.from_iterable(tokens(text(soup(c[-1]))) for c in all_composers)\n",
    "    counter = collections.Counter(all_tokens)\n",
    "    vocab = {i: token for i, (token, _) in enumerate(counter.most_common(MAX_VOCAB_SIZE))}\n",
    "    vocab[len(vocab)] = '<unk>'\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab()\n",
    "\n",
    "path = '{}.vocab'.format(MAX_VOCAB_SIZE)\n",
    "with open(path, 'wb') as f:\n",
    "    pickled = pickle.dump(vocab, f)\n",
    "\n",
    "files.download(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "hNXL5cVjZJ1G",
    "outputId": "60aad415-dac6-4b7a-c9da-25ef11111be4"
   },
   "outputs": [],
   "source": [
    "# Load vocab from disk\n",
    "MAX_VOCAB_SIZE = 10000\n",
    "\n",
    "with open('../data/{}.vocab'.format(MAX_VOCAB_SIZE), 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "assert len(vocab) <= MAX_VOCAB_SIZE + 1, 'Loaded vocab must match max vocab size'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "DVgZ4g4yY8lb",
    "outputId": "aada9665-4079-4f30-8a36-90f3f2e31be4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py:44: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 552s 3s/step - loss: 9.1931 - categorical_accuracy: 0.0677\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 630s 3s/step - loss: 9.1567 - categorical_accuracy: 0.0773\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 589s 3s/step - loss: 9.1161 - categorical_accuracy: 0.0806\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 609s 3s/step - loss: 9.0758 - categorical_accuracy: 0.0819\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 609s 3s/step - loss: 9.0410 - categorical_accuracy: 0.0781\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 617s 3s/step - loss: 8.9968 - categorical_accuracy: 0.0819\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 624s 3s/step - loss: 8.9635 - categorical_accuracy: 0.0813\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 600s 3s/step - loss: 8.9294 - categorical_accuracy: 0.0764\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 634s 3s/step - loss: 8.8891 - categorical_accuracy: 0.0803\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 622s 3s/step - loss: 8.8531 - categorical_accuracy: 0.0786\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 635s 3s/step - loss: 8.8140 - categorical_accuracy: 0.0758\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 599s 3s/step - loss: 8.7651 - categorical_accuracy: 0.0808\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 648s 3s/step - loss: 8.7283 - categorical_accuracy: 0.0825\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 620s 3s/step - loss: 8.6958 - categorical_accuracy: 0.0813\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 632s 3s/step - loss: 8.6912 - categorical_accuracy: 0.0720\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 632s 3s/step - loss: 8.6231 - categorical_accuracy: 0.0856\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 626s 3s/step - loss: 8.5951 - categorical_accuracy: 0.0742\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 637s 3s/step - loss: 8.5682 - categorical_accuracy: 0.0753\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 617s 3s/step - loss: 8.4967 - categorical_accuracy: 0.0847\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 639s 3s/step - loss: 8.4828 - categorical_accuracy: 0.0798\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 623s 3s/step - loss: 8.4467 - categorical_accuracy: 0.0788\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 643s 3s/step - loss: 8.4076 - categorical_accuracy: 0.0764\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 610s 3s/step - loss: 8.3788 - categorical_accuracy: 0.0813\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 648s 3s/step - loss: 8.3221 - categorical_accuracy: 0.0819\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 614s 3s/step - loss: 8.3099 - categorical_accuracy: 0.0772\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 637s 3s/step - loss: 8.2612 - categorical_accuracy: 0.0766\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 629s 3s/step - loss: 8.2144 - categorical_accuracy: 0.0813\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 634s 3s/step - loss: 8.1839 - categorical_accuracy: 0.0827\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 639s 3s/step - loss: 8.1039 - categorical_accuracy: 0.0822\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 623s 3s/step - loss: 8.1097 - categorical_accuracy: 0.0780\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 648s 3s/step - loss: 8.1011 - categorical_accuracy: 0.0750\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 619s 3s/step - loss: 8.0314 - categorical_accuracy: 0.0784\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 650s 3s/step - loss: 8.0152 - categorical_accuracy: 0.0766\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 626s 3s/step - loss: 8.0186 - categorical_accuracy: 0.0717\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 654s 3s/step - loss: 7.9239 - categorical_accuracy: 0.0792\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 628s 3s/step - loss: 7.8523 - categorical_accuracy: 0.0855\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 635s 3s/step - loss: 7.9067 - categorical_accuracy: 0.0773\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 642s 3s/step - loss: 7.8636 - categorical_accuracy: 0.0848\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 643s 3s/step - loss: 7.8545 - categorical_accuracy: 0.0772\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 636s 3s/step - loss: 7.8147 - categorical_accuracy: 0.0759\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 624s 3s/step - loss: 7.8148 - categorical_accuracy: 0.0692\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 643s 3s/step - loss: 7.7343 - categorical_accuracy: 0.0825\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 626s 3s/step - loss: 7.7499 - categorical_accuracy: 0.0792\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 664s 3s/step - loss: 7.6980 - categorical_accuracy: 0.0800\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 626s 3s/step - loss: 7.6997 - categorical_accuracy: 0.0759\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 664s 3s/step - loss: 7.6592 - categorical_accuracy: 0.0770\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 613s 3s/step - loss: 7.6414 - categorical_accuracy: 0.0784\n",
      "Epoch 48/100\n",
      "114/200 [================>.............] - ETA: 4:27 - loss: 7.5874 - categorical_accuracy: 0.0779"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7179ce284881>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_composers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-7179ce284881>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, window_size, vocab_size)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         workers=4)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    785\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Make sure to rethrow the first exception in the queue, if any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab_lower = {token.lower(): i for i, token in vocab.items()}\n",
    "\n",
    "\n",
    "def token_to_token_id(token):\n",
    "    return vocab_lower.get(token.lower(), vocab_lower['<unk>'])\n",
    "\n",
    "\n",
    "def token_ids(tokens):\n",
    "    return [token_to_token_id(token) for token in tokens]\n",
    "\n",
    " \n",
    "def training_data(window_size, vocab_size):\n",
    "    assert window_size % 2 == 0, 'window_size must be even'\n",
    "    offset = window_size // 2\n",
    "  \n",
    "    for composer in itertools.cycle(all_composers):\n",
    "        t_ids = token_ids(tokens(text(soup(composer[-1]))))\n",
    "        num_tokens = len(t_ids)\n",
    "    \n",
    "        if num_tokens <= window_size:\n",
    "            continue\n",
    "    \n",
    "        target_idx = random.randint(offset, (num_tokens - offset) - 1)\n",
    "    \n",
    "        target_id = t_ids[target_idx]\n",
    "      \n",
    "        context_window = t_ids[target_idx-offset:target_idx] + t_ids[target_idx+1:target_idx+offset+1]\n",
    "    \n",
    "        yield composer[0], context_window, to_categorical(target_id, num_classes=vocab_size)\n",
    "    \n",
    "    \n",
    "def batch(data, batch_size=32):\n",
    "    while True:\n",
    "        batch = itertools.islice(data, batch_size)\n",
    "    \n",
    "        x_1 = []\n",
    "        x_2 = []\n",
    "        y = []\n",
    "    \n",
    "        for item in batch:\n",
    "            composer_id, context_window, target_ids = item\n",
    "      \n",
    "            x_1.append(composer_id)\n",
    "            x_2.append(context_window)\n",
    "            y.append(target_ids)\n",
    "      \n",
    "        yield [np.array(x_1), np.array(x_2)], np.array(y)\n",
    "\n",
    "\n",
    "def build_model(window_size, vocab_size, num_composers):\n",
    "    sequence_input = Input(shape=(window_size,))\n",
    "    composer_input = Input(shape=(1,))\n",
    "  \n",
    "    embedded_sequence = Embedding(input_dim=vocab_size, output_dim=300, input_length=window_size)(sequence_input)\n",
    "    embedded_composer = Embedding(input_dim=num_composers, output_dim=300, input_length=1)(composer_input)\n",
    "  \n",
    "  \n",
    "    embedded = Concatenate(axis=1)([embedded_composer, embedded_sequence])\n",
    "    split = Lambda(lambda t: tf.split(t, window_size + 1, axis=1))(embedded)\n",
    "    averaged = Average()(split)\n",
    "    squeezed = Lambda(lambda t: tf.squeeze(t, axis=1))(averaged)\n",
    "  \n",
    "    softmax = Dense(vocab_size, activation='softmax')(squeezed)\n",
    "  \n",
    "    model = Model(inputs=[composer_input, sequence_input], outputs=softmax)\n",
    "  \n",
    "    sgd = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['categorical_accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model, window_size, vocab_size):\n",
    "    history = model.fit_generator(\n",
    "        batch(training_data(window_size, vocab_size)),\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='loss', patience=10)\n",
    "          ],\n",
    "        steps_per_epoch=200,\n",
    "        epochs=100,\n",
    "        use_multiprocessing=True,\n",
    "        workers=4)\n",
    "  \n",
    "    return history\n",
    "\n",
    "    \n",
    "# 1. produce sliding window of context-target pairs from input tokens\n",
    "# 2. sample a random context-target pair from a random composer\n",
    "# 3. feed into network\n",
    "# 4. .: a batch is input => (batch_size * 1), (batch_size * context window length); output => (batch size * 1)\n",
    "# 5. later, extract learned embeddings of composers as our vectors.\n",
    "\n",
    "\n",
    "window_size = 8\n",
    "vocab_size = len(vocab)\n",
    "num_composers = len(all_composers)\n",
    "\n",
    "model = build_model(window_size, vocab_size, num_composers)\n",
    "history = train_model(model, window_size, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/d2v-sgd-lr0.001-epochs-47-steps-200-vocab-10000.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_to_composer_embeddings(model):\n",
    "    return np.array(model.layers[2].get_weights()[0])\n",
    "\n",
    "composer_embeddings = model_to_composer_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvxSsMF0IGPq"
   },
   "outputs": [],
   "source": [
    "def similar_doc2vec(composer_id):\n",
    "    print('Using doc2vec model')\n",
    "    composer = id_to_composer[composer_id]\n",
    "    composer_id = composer[0]\n",
    "    composer_embedding = composer_embeddings[composer_id]\n",
    "    \n",
    "    def similarity_to_target(c_id):\n",
    "        similar_composer_embedding = composer_embeddings[c_id]\n",
    "        return distance.cosine(composer_embedding, similar_composer_embedding)\n",
    "    \n",
    "    return sorted((c[0] for c in all_composers if c[0] != composer_id), key=similarity_to_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biYfJYl8u3ka"
   },
   "source": [
    "TODO\n",
    "---\n",
    "\n",
    "1. Create batch of data (word ids, composer ids, windows)\n",
    "2. Save\n",
    "3. Run for an epoch of training time\n",
    "4. Early stopping criterion\n",
    "5. At test, calculate similarity between embedded composers and all other composers?\n",
    "6. Possibly, have validation criterion based on wikipedia baseline\n",
    "7. Preload Google News embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "id": "mVlSyk4FHRtD",
    "outputId": "06dca54a-fb7b-4d60-e18a-6343935381e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You might like:\n",
      "Using doc2vec model\n",
      "Nicolao Dorati (https://en.wikipedia.org/wiki/Nicolao_Dorati)\n",
      "Elfrida Andrée (https://en.wikipedia.org/wiki/Elfrida_Andr%C3%A9e)\n",
      "Emmanuel Fisher (https://en.wikipedia.org/wiki/Emmanuel_Fisher)\n"
     ]
    }
   ],
   "source": [
    "# Pick and execute model; print results\n",
    "\n",
    "def similarity_function(model_name):\n",
    "    if model_name == 'wikipedia-links':\n",
    "        return similar_wikipedia_links\n",
    "    elif model_name == 'spotify':\n",
    "        return similar_spotify\n",
    "    elif model_name == 'doc2vec':\n",
    "        return similar_doc2vec\n",
    "    else:\n",
    "        raise ValueError('Invalid model: {}'.format(model))\n",
    "\n",
    "\n",
    "print('You might like:')\n",
    "for similar_id in itertools.islice(similarity_function(model_name)(composer_id), 3):\n",
    "    similar_composer = id_to_composer[similar_id]\n",
    "    print('{} ({})'.format(similar_composer[1], similar_composer[-1]))  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "composers-doc2vec-keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
